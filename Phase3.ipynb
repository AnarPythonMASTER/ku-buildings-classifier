{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d44b0b",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "583c8b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.metrics import Accuracy, F1Score, Precision, Recall\n",
    "from keras.optimizers import SGD, Adam, Adagrad, RMSprop, Nadam, AdamW\n",
    "from keras.src.losses import loss\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import MobileNetV2 # we need to be able to use pretrained model\n",
    "\n",
    "BASE_DIR = os.getcwd() # it will be used in whole processes to easily access folders\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6ce96",
   "metadata": {},
   "source": [
    "## Variable initialization (that will help us to update parameters easily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = os.path.join(BASE_DIR, \"dataset\", \"train\")\n",
    "VAL_DATA_DIR = os.path.join(BASE_DIR, \"dataset\", \"val\")\n",
    "FULL_DATA = True # if set as True then it will train over concatenated data (train + val), if false then only train (as usual)\n",
    "\n",
    "\n",
    "MODEL_SAVE_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "MODEL_NAME = 'cnn_model_phase3_full_data'\n",
    "TESTING_MODE = False # if it is set as True then it will help you easily test pipeline\n",
    "# !!! WARNING !!!: if you set as True it can result saving wrong model\n",
    "\n",
    "# Parameters that will be used in modeling\n",
    "MOMENTUM= 0.9\n",
    "NESTEROV=True\n",
    "\n",
    "INPUT_IMG_SIZE = (224, 168)\n",
    "NUM_CLASSES = 9\n",
    "CHANNELS = 3\n",
    "\n",
    "EPOCHS = 7\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 15\n",
    "BATCH = 32\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eddbdf",
   "metadata": {},
   "source": [
    "### Target class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b86fbec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'c:\\Users\\Shahbaz\\Desktop\\data science\\from git\\ku-buildings-classifier\\dataset\\train':\n",
      "basement\n",
      "church\n",
      "entrance\n",
      "georgianum\n",
      "kreuztor\n",
      "ku\n",
      "pink\n",
      "room\n",
      "wfi\n"
     ]
    }
   ],
   "source": [
    "# target class names\n",
    "if os.path.isdir(TRAIN_DATA_DIR):\n",
    "    folder_contents = os.listdir(TRAIN_DATA_DIR)\n",
    "    print(f\"Contents of '{TRAIN_DATA_DIR}':\")\n",
    "    for item in folder_contents:\n",
    "        print(item)\n",
    "else:\n",
    "    print(f\"Error: '{TRAIN_DATA_DIR}' is not a valid directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a36fad",
   "metadata": {},
   "source": [
    "## Train - Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bbd9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data (Color Mode: rgb):\n",
      "Found 6769 files belonging to 9 classes.\n",
      "\n",
      "Loading Validation Data:\n",
      "Found 1698 files belonging to 9 classes.\n",
      "\n",
      "\n",
      "Classes of train: ['basement', 'church', 'entrance', 'georgianum', 'kreuztor', 'ku', 'pink', 'room', 'wfi']\n",
      "Classes of validation: ['basement', 'church', 'entrance', 'georgianum', 'kreuztor', 'ku', 'pink', 'room', 'wfi']\n"
     ]
    }
   ],
   "source": [
    "# 1) Train split\n",
    "print(f\"Loading Training Data (Color Mode: rgb):\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH,\n",
    "    image_size=INPUT_IMG_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# 2) Validation split\n",
    "print(\"\\nLoading Validation Data:\")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DATA_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH,\n",
    "    image_size=INPUT_IMG_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "print(\"Classes of train:\", train_ds.class_names)\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "print(\"Classes of validation:\", val_ds.class_names)\n",
    "num_classes = len(val_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fe04e",
   "metadata": {},
   "source": [
    "### writing target class labels as json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a256798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved class mapping to C:\\Users\\Shahbaz\\Desktop\\data science\\from git\\ku-buildings-classifier\\models\\class_mapping.json\n",
      "Mapping dictionary: {0: 'basement', 1: 'church', 2: 'entrance', 3: 'georgianum', 4: 'kreuztor', 5: 'ku', 6: 'pink', 7: 'room', 8: 'wfi'}\n"
     ]
    }
   ],
   "source": [
    "# extract the class names (Keras automatically sorts them) to use easily in testing\n",
    "class_names = train_ds.class_names\n",
    "class_mapping = {i: name for i, name in enumerate(class_names)}\n",
    "\n",
    "# save it as a JSON in your models directory\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "mapping_path = os.path.join(MODEL_SAVE_DIR, 'class_mapping.json')\n",
    "\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump(class_mapping, f, indent=4)\n",
    "\n",
    "print(f\"\\nSuccessfully saved class mapping to {mapping_path}\")\n",
    "print(\"Mapping dictionary:\", class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4866fa",
   "metadata": {},
   "source": [
    "## ⚠️ Important Note on Data Normalization\n",
    "\n",
    "Standard image normalization (dividing by `255.0`) is intentionally skipped in the data pipeline. \n",
    "\n",
    "Because we are using **MobileNetV2** as our base model, it specifically requires pixel values to be scaled between `[-1, 1]` rather than the standard `[0, 1]`. \n",
    "\n",
    "To handle this cleanly, the MobileNet-specific rescaling is built directly into the sequential model architecture rather than mapping it to the dataset:\n",
    "`layers.Rescaling(1./127.5, offset=-1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE DRY RUN LOGIC (smoke test before the attack)\n",
    "if TESTING_MODE:\n",
    "    print(\"testing mode activated and it helps smoke test\")\n",
    "    train_ds = train_ds.take(2)\n",
    "    val_ds = val_ds.take(1)\n",
    "\n",
    "# Speed, this is not that important but recommended\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a925330",
   "metadata": {},
   "source": [
    "### count of train data and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b926f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 168, 3)\n",
      "Number of total training batches: 212\n",
      "Number of total training images (approximately): 6784\n"
     ]
    }
   ],
   "source": [
    "# information of train data\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)\n",
    "\n",
    "total_images = len(train_ds) * BATCH\n",
    "print(f\"Number of total training batches: {len(train_ds)}\")\n",
    "print(f\"Number of total training images (approximately): {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aebcfd0",
   "metadata": {},
   "source": [
    "## Pretrained model: MobileNet V2\n",
    "* **`include_top = False`**: Avoids using the 1000-class output layer of the pretrained model. By avoiding the original classification (the last layer), so we can attach our own custom Dense layers.\n",
    "* **`weights = 'imagenet'`**: Initializes the model with parameters pre-trained on the massive ImageNet dataset (over 1 million images). Instead of starting from scratch with random, untrained weights, the model already acts as a powerful feature extractor that knows how to identify fundamental visual patterns like edges, corners, and textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e353dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahbaz\\AppData\\Local\\Temp\\ipykernel_9988\\1595368369.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  basemodel = tf.keras.applications.MobileNetV2(\n"
     ]
    }
   ],
   "source": [
    "basemodel = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224,168,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "# basemodel.summary() # you may get information about pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849bce24",
   "metadata": {},
   "source": [
    "### We are seting the weights fixed or freezed so they do not get  (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "941ee319",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.trainable = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781639f1",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "Data augmentation is a technique used to artificially expand the training dataset by applying random transformations to the images (such as rotating, zooming, or flipping). \n",
    "\n",
    "* **Reduces overfitting (a bit):** By using different type of the input images, it prevents model from simply memorizing the repeated patterns of the training data.\n",
    "* **Improves generalization:** It forces the model to learn the actual structural features of the KU buildings. This ensures the model can still accurately recognize a building in the real world, even if a user's test photo is taken from a weird angle, zoomed in, or slightly tilted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79295cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomTranslation(0.1,0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fab213",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= keras.Sequential([\n",
    "    layers.Input(shape=(224,168,3)),\n",
    "    data_augmentation,\n",
    "    layers.Rescaling(1./127.5,offset=-1),\n",
    "    basemodel,\n",
    "    layers.GlobalAveragePooling2D(), ## Prof. Voigtlaenders suggestion to use this instead of Flatten()\n",
    "    \n",
    "    layers.Dense(256,activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    layers.BatchNormalization(), # i learned this new, so we normalize the outputs of the layers so that mean =0 and var=1\n",
    "    layers.Dropout(0.4), # also from the deep learning class\n",
    "    \n",
    "    layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(64,activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(32,activation=\"relu\",kernel_initializer=\"he_normal\"),\n",
    "    \n",
    "    layers.Dense(NUM_CLASSES,activation=\"softmax\") # num_class in our class in PHASE 3 is equal to 9 since we have combined multiple subclasses to a unified class, before in phase 1 it was 21 categories\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b570e",
   "metadata": {},
   "source": [
    "### Early Stopping & Restoring Weights\n",
    "Early stopping acts as a safety brake during training. It monitors the model's performance and automatically stops the iterations if the accuracy stops improving for a set amount of time (our `patience` variable). \n",
    "\n",
    "* **`restore_best_weights = True`**: If the model starts to overfit and actually gets worse during those extra patience epochs, this setting forces Keras to \"rewind\" and grab the exact parameters from the model's absolute best epoch. This prevents us from accidentally saving a ruined, overfitted version of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a587611",
   "metadata": {},
   "source": [
    "### Early stopping: helps model to stop iterations when it stops improving over the given metric (**`monitor = 'val_loss'`**)\n",
    "* **`restore_best_weights = True`** helps us to convert the model parameters to 5 step previous (**`patience = 5`**) version which helps us to prevent meaningless overfitting over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4fe608",
   "metadata": {},
   "outputs": [],
   "source": [
    "early=EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12830d06",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae586be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 779ms/step - accuracy: 0.7425 - loss: 0.8258\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shahbaz\\Desktop\\data science\\from git\\ku-buildings-classifier\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 766ms/step - accuracy: 0.9275 - loss: 0.2415\n",
      "Epoch 3/7\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 805ms/step - accuracy: 0.9421 - loss: 0.1809\n",
      "Epoch 4/7\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 780ms/step - accuracy: 0.9470 - loss: 0.1596\n",
      "Epoch 5/7\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 807ms/step - accuracy: 0.9517 - loss: 0.1491\n",
      "Epoch 6/7\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 707ms/step - accuracy: 0.9613 - loss: 0.1231\n",
      "Epoch 7/7\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 720ms/step - accuracy: 0.9636 - loss: 0.1057\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# if FULL_DATA is set as True in the model parameters initialization step then it will train over full data\n",
    "if FULL_DATA:\n",
    "    full_ds = train_ds.concatenate(val_ds)\n",
    "    model.fit(\n",
    "        full_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early]\n",
    "    )\n",
    "else:\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95cc60",
   "metadata": {},
   "source": [
    "### saving model outputs as both keras and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb0b8ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model successfully saved to C:\\Users\\Shahbaz\\Desktop\\data science\\from git\\ku-buildings-classifier\\models\\cnn_model_phase3_full_data.keras\n"
     ]
    }
   ],
   "source": [
    "# save model outputs\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "save_path = os.path.join(MODEL_SAVE_DIR, f\"{MODEL_NAME}.keras\") # modern recommended version\n",
    "\n",
    "model.save(save_path)\n",
    "print(f\"\\nModel successfully saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters successfully isolated and saved to C:\\Users\\Shahbaz\\Desktop\\data science\\from git\\ku-buildings-classifier\\models\\cnn_model_phase3_full_data_final.weights.h5\n"
     ]
    }
   ],
   "source": [
    "final_weights_path = os.path.join(MODEL_SAVE_DIR, f'{MODEL_NAME}_final.weights.h5')\n",
    "model.save_weights(final_weights_path)\n",
    "print(f\"Final parameters successfully isolated and saved to {final_weights_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112968d7",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308513b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total layers in base model: 154\n",
      "Frozen layers: 0 to 123\n",
      "Trainable layers (Fine-tuning): 124 to 153\n"
     ]
    }
   ],
   "source": [
    "basemodel.trainable = True # we set all layers being trainable (removing freeze)\n",
    "\n",
    "# find out how many layers MobileNetV2 has\n",
    "total_layers = len(basemodel.layers)\n",
    "print(f\"Total layers of base model: {total_layers}\")\n",
    "\n",
    "# calculate the cutoff point (if we want to tune over only last 30 layers of pretrained model)\n",
    "fine_tune_at = total_layers - 30\n",
    "\n",
    "# freeze everything before the cutoff point (again basemodel.trainable = False for first layers till last 30)\n",
    "for layer in basemodel.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Frozen layers: 0 to {fine_tune_at - 1}\")\n",
    "print(f\"Trainable layers (Fine-tuning): {fine_tune_at} to {total_layers - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25fb0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 808ms/step - accuracy: 0.9645 - loss: 0.1113 - val_accuracy: 0.9552 - val_loss: 0.1252\n",
      "Epoch 2/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 853ms/step - accuracy: 0.9644 - loss: 0.1127 - val_accuracy: 0.9576 - val_loss: 0.1191\n",
      "Epoch 3/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 847ms/step - accuracy: 0.9617 - loss: 0.1174 - val_accuracy: 0.9576 - val_loss: 0.1204\n",
      "Epoch 4/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 913ms/step - accuracy: 0.9660 - loss: 0.1095 - val_accuracy: 0.9570 - val_loss: 0.1169\n",
      "Epoch 5/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 878ms/step - accuracy: 0.9653 - loss: 0.1090 - val_accuracy: 0.9570 - val_loss: 0.1153\n",
      "Epoch 6/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 931ms/step - accuracy: 0.9672 - loss: 0.1054 - val_accuracy: 0.9582 - val_loss: 0.1176\n",
      "Epoch 7/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 972ms/step - accuracy: 0.9662 - loss: 0.1142 - val_accuracy: 0.9588 - val_loss: 0.1141\n",
      "Epoch 8/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 959ms/step - accuracy: 0.9650 - loss: 0.1075 - val_accuracy: 0.9582 - val_loss: 0.1153\n",
      "Epoch 9/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 937ms/step - accuracy: 0.9668 - loss: 0.1031 - val_accuracy: 0.9600 - val_loss: 0.1169\n",
      "Epoch 10/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 883ms/step - accuracy: 0.9660 - loss: 0.1078 - val_accuracy: 0.9600 - val_loss: 0.1142\n",
      "Epoch 11/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 974ms/step - accuracy: 0.9722 - loss: 0.0886 - val_accuracy: 0.9600 - val_loss: 0.1101\n",
      "Epoch 12/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 947ms/step - accuracy: 0.9654 - loss: 0.1075 - val_accuracy: 0.9582 - val_loss: 0.1164\n",
      "Epoch 13/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 922ms/step - accuracy: 0.9700 - loss: 0.0997 - val_accuracy: 0.9576 - val_loss: 0.1187\n",
      "Epoch 14/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 976ms/step - accuracy: 0.9718 - loss: 0.0908 - val_accuracy: 0.9582 - val_loss: 0.1118\n",
      "Epoch 15/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 1s/step - accuracy: 0.9718 - loss: 0.0925 - val_accuracy: 0.9588 - val_loss: 0.1137\n",
      "Epoch 16/25\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 959ms/step - accuracy: 0.9718 - loss: 0.0877 - val_accuracy: 0.9588 - val_loss: 0.1116\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    }
   ],
   "source": [
    "history_full_finetune = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=25,\n",
    "    callbacks=[early]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffcfd8",
   "metadata": {},
   "source": [
    "### saving the fine-tuned model outputs as keras, weights and tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3672a170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model successfully saved to C:\\Users\\Shahbaz\\Desktop\\data science\\from git\\ku-buildings-classifier\\models\\fine_tuned.keras\n"
     ]
    }
   ],
   "source": [
    "# save model outputs\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "save_path = os.path.join(MODEL_SAVE_DIR, f\"fine_tuned.keras\") # modern recommended version\n",
    "\n",
    "model.save(save_path)\n",
    "print(f\"\\nModel successfully saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d95aa65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters successfully isolated and saved to C:\\Users\\Shahbaz\\Desktop\\data science\\from git\\ku-buildings-classifier\\models\\fine_tuned_final.weights.h5\n"
     ]
    }
   ],
   "source": [
    "final_weights_path = os.path.join(MODEL_SAVE_DIR, f'fine_tuned_final.weights.h5')\n",
    "model.save_weights(final_weights_path)\n",
    "print(f\"Final parameters successfully isolated and saved to {final_weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tflite conversion\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = os.path.join(MODEL_SAVE_DIR, \"fine_tuned_final.tflite\")\n",
    "\n",
    "# save model as tflite\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4adf1",
   "metadata": {},
   "source": [
    "## Test the results over 3 models on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe11f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set base paths\n",
    "BASE_DIR = os.getcwd()\n",
    "MAPPING_PATH = os.path.join(BASE_DIR, \"models\", \"class_mapping.json\")\n",
    "with open(MAPPING_PATH, 'r') as f:\n",
    "    loaded_class_mapping = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "test_folders = ['old_test', 'new_test']\n",
    "models = [\n",
    "    # 'cnn_model_phase1.keras', # model phase 1\n",
    "    'cnn_model_phase2.keras', # model phase 2\n",
    "    'cnn_model_phase3_full_data_final.weights.h5', # model phase 3 (with pretrained model)\n",
    "    'fine_tuned_final.weights.h5' # with fine-tuned pretrained model\n",
    "]\n",
    "\n",
    "all_results = [] # we will collect all outputs\n",
    "\n",
    "def predict_single_image(image_path, model, class_mapping, model_name):\n",
    "    # get target size from the loaded model\n",
    "    img_size = (model.input_shape[1], model.input_shape[2])\n",
    "    \n",
    "    img = tf.keras.utils.load_img(image_path, target_size=img_size)\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # NORMALIZATION LOGIC:\n",
    "    if model_name.endswith('.keras'):\n",
    "        img_array = img_array / 255.0\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_index = int(np.argmax(predictions[0]))\n",
    "    confidence_score = float(np.max(predictions[0]) * 100)\n",
    "    \n",
    "    return class_mapping[predicted_index], confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2808d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Loading Model: cnn_model_phase2.keras\n",
      "========================================\n",
      "Keras model loaded successfully!\n",
      "  -> Scanning folder: old_test...\n",
      "  -> Scanning folder: new_test...\n",
      "\n",
      "========================================\n",
      "Loading Model: cnn_model_phase3_full_data_final.weights.h5\n",
      "========================================\n",
      "Weights loaded successfully!\n",
      "  -> Scanning folder: old_test...\n",
      "  -> Scanning folder: new_test...\n",
      "\n",
      "========================================\n",
      "Loading Model: fine_tuned_final.weights.h5\n",
      "========================================\n",
      "Weights loaded successfully!\n",
      "  -> Scanning folder: old_test...\n",
      "  -> Scanning folder: new_test...\n",
      "\n",
      "Compiling data into Excel...\n"
     ]
    }
   ],
   "source": [
    "# We loop over MODELS first, so we don't waste time reloading the same model twice\n",
    "for model_name in models:\n",
    "    MODEL_PATH = os.path.join(BASE_DIR, \"models\", model_name)\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Loading Model: {model_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    if model_name.endswith('.weights.h5'):\n",
    "        # Build the empty Phase 3 architecture\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(224,168,3)),\n",
    "            data_augmentation,\n",
    "            tf.keras.layers.Rescaling(1./127.5, offset=-1),\n",
    "            basemodel,\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            \n",
    "            tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.4),\n",
    "            \n",
    "            tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            \n",
    "            tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            \n",
    "            tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "            tf.keras.layers.Dense(9, activation=\"softmax\") # 9 classes for Phase 3\n",
    "        ])\n",
    "        model.load_weights(MODEL_PATH)\n",
    "        print(\"Weights loaded successfully!\")\n",
    "        \n",
    "    else:\n",
    "        # Load standard Phase 1/2 Keras models\n",
    "        model = tf.keras.models.load_model(MODEL_PATH)\n",
    "        print(\"Keras model loaded successfully!\")\n",
    "\n",
    "    # 3. Loop through test folders for the current model\n",
    "    for folder_name in test_folders:\n",
    "        test_folder_path = os.path.join(BASE_DIR, \"test_images\", folder_name)\n",
    "        print(f\"  -> Scanning folder: {folder_name}...\")\n",
    "        \n",
    "        for filename in os.listdir(test_folder_path):\n",
    "            if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            full_image_path = os.path.join(test_folder_path, filename)\n",
    "            \n",
    "            # Predict\n",
    "            predicted_building, confidence_score = predict_single_image(full_image_path, model, loaded_class_mapping, model_name)\n",
    "            \n",
    "            # Save the result to our dictionary list\n",
    "            all_results.append({\n",
    "                \"Model Name\": model_name,\n",
    "                \"Test Folder\": folder_name,\n",
    "                \"Image Name\": filename,\n",
    "                \"Predicted Class\": predicted_building.upper(),\n",
    "                \"Confidence (%)\": round(confidence_score, 2)\n",
    "            })\n",
    "\n",
    "# 4. Export to Excel\n",
    "print(\"\\nCompiling data into Excel...\")\n",
    "df = pd.DataFrame(all_results)\n",
    "excel_path = os.path.join(BASE_DIR, \"detailed_model_outputs.xlsx\")\n",
    "df.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dab322a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL MODEL ACCURACY REPORT:\n",
      "cnn_model_phase2.keras                       :  42.55%\n",
      "cnn_model_phase3_full_data_final.weights.h5  :  87.23%\n",
      "fine_tuned_final.weights.h5                  :  93.62%\n"
     ]
    }
   ],
   "source": [
    "valid_classes = [name.upper() for name in loaded_class_mapping.values()]\n",
    "\n",
    "def find_true_class(filename):\n",
    "    filename_upper = filename.upper()\n",
    "    for class_name in valid_classes:\n",
    "        if class_name in filename_upper:\n",
    "            return class_name\n",
    "    return \"UNKNOWN\" # Just in case a file name has no class in it\n",
    "\n",
    "df['True Class'] = df['Image Name'].apply(find_true_class)\n",
    "df['Correct'] = df['True Class'] == df['Predicted Class']\n",
    "\n",
    "accuracy_summary = df.groupby('Model Name')['Correct'].mean() * 100\n",
    "\n",
    "print(\"FINAL MODEL ACCURACY REPORT:\")\n",
    "for model_name, accuracy in accuracy_summary.items():\n",
    "    print(f\"{model_name:<45}: {accuracy:>6.2f}%\")\n",
    "\n",
    "analysis_excel_path = os.path.join(BASE_DIR, \"model_accuracy_analysis.xlsx\")\n",
    "df.to_excel(analysis_excel_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
